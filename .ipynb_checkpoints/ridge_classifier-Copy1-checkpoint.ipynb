{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "flush-warehouse",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/US_category_id.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d66ac9a466d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/US_category_id.json\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/US_category_id.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "f = open(\"../data/US_category_id.json\",)\n",
    "\n",
    "data = json.load(f)\n",
    "\n",
    "categoryMap = {}\n",
    "for i in data[\"items\"]:\n",
    "    categoryMap[i[\"id\"]]  = i[\"snippet\"][\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-africa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/USvideos.csv\")\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-shelf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-venezuela",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-williams",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.columns[[0,1,5,7,8,9,10,11,12,13,14]], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-truth",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-polls",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove rows with no values\n",
    "rows_with_nan = [index for index, row in df.iterrows() if row.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-print",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Rows with NaN: \", len(rows_with_nan))\n",
    "df.drop(rows_with_nan, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-madrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()\n",
    "df.drop_duplicates(subset=[\"title\",\"channel_title\",\"tags\",\"description\"], inplace=True)\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consistent-release",
   "metadata": {},
   "outputs": [],
   "source": [
    "#borrow kduong for cleaning dataset\n",
    "import re\n",
    "\n",
    "def preProcess(data, length):\n",
    "    data =  re.sub('[^a-zA-Z0-9 \\n\\...]', ' ', str(data))\n",
    "    string_encode = str(data).encode(\"ascii\", \"ignore\")\n",
    "    string_decode = string_encode.decode()\n",
    "    data = string_decode\n",
    "    dataArr = str(data).strip().split(\" \")\n",
    "    for i in  reversed(range(len(dataArr))):\n",
    "        dataArr[i] = str(dataArr[i]).lower()\n",
    "        if len(dataArr[i]) == 0:\n",
    "            del dataArr[i]\n",
    "        elif len(dataArr[i]) < length:\n",
    "            del dataArr[i]\n",
    "    dataArr = \";\".join(dataArr)\n",
    "    return dataArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-enterprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "videoData = []\n",
    "for i in range(df.count()[0]):\n",
    "    current_vid = df.iloc[i]\n",
    "    row = []\n",
    "    channel_title = preProcess(current_vid[\"channel_title\"], 0)\n",
    "    title = preProcess(current_vid[\"title\"], 4)\n",
    "    tags = preProcess(current_vid[\"tags\"], 4)\n",
    "    description = preProcess(current_vid[\"description\"], 4)\n",
    "    category = categoryMap[str(current_vid[\"category_id\"])]\n",
    "    \n",
    "    row.append(channel_title)\n",
    "    row.append(title)\n",
    "    row.append(tags)\n",
    "    row.append(description)\n",
    "    row.append(category)\n",
    "    videoData.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-oregon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv  \n",
    "\n",
    "header = ['Video Title', 'Channel Title', 'Tags', 'Description', 'Category']\n",
    "\n",
    "with open('video_data.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    # write the header\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(videoData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-crystal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "file = 'video_data.csv'\n",
    "data = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-chance",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"All\"] = data[\"Tags\"] + \";\" + data[\"Video Title\"] + \";\" +  data[\"Description\"] + \";\" +  data[\"Channel Title\"]\n",
    "vectorizer = CountVectorizer(stop_words = \"english\")\n",
    "all_features = vectorizer.fit_transform(data['All'].fillna(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-jumping",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(all_features, data[\"Category\"], test_size = 0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RidgeClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "print(\"Score: \", clf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fundamental-naples",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(y_test, clf.predict(x_test),average='weighted')\n",
    "print(\"F1-Score: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-british",
   "metadata": {},
   "outputs": [],
   "source": [
    "#borrow kduong for category prediction\n",
    "def checkCategory(example):\n",
    "    emptyArr = []\n",
    "    emptyArr.append(example)\n",
    "    doc_term_matrix = vectorizer.transform(emptyArr)\n",
    "    clf.predict(doc_term_matrix)\n",
    "    class_prob_list = clf.decision_function(doc_term_matrix)[0]\n",
    "    map = {}\n",
    "    for i in range(len(class_prob_list)):\n",
    "        map[str(clf.classes_[i])] = class_prob_list[i]\n",
    "    sort_classes = sorted(map.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(example + \" is most likely category: \" + str(sort_classes[0]))\n",
    "    print(\" \")\n",
    "    print(\"Probabilities\")\n",
    "    for i in sort_classes:\n",
    "        print(i[0], i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-branch",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkCategory(\"Bruce Almighty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-principle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
